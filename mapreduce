__author__ = 'Xavi Domenech & Manuel Rojo'

import string
import multiprocessing


def Map(L):
    print multiprocessing.current_process().name
    ip =[]
    month= []
    year= []
    for i, datum in enumerate(L):
        a=string.split(datum, '	')
        ip.append((a[0],1))
        month.append((a[4],1))
        year.append((a[5],1))

    multiprocessing.current_process().__setattr__('ip',ip)
    multiprocessing.current_process().__setattr__('month',month)
    multiprocessing.current_process().__setattr__('year',year)

    return None


def Reduce(Mapping):
    return None


def uniformTest(size):
    p = [multiprocessing.Pool(1) for i in range(size)]
    for pool in p:
        pool.terminate()
        pool.join()


def randomTest(size):
    p = multiprocessing.Pool(size)
    p.terminate()
    p.join()


def num_lines_file(filename, num_processes):
    """
    :param filename: Name of the file to count
    :param num_processes: Number of processes to do the map/reduce
    :return: Number of lines to process for each process
    """
    lines_process = []

    num_lines = sum(1 for line in open(filename)) # Count number of lines in the file

    rest = num_lines % num_processes

    for i in range(0, num_processes):
        if i == num_processes - 1:
            lines_process.append(int(num_lines / num_processes) + rest)
        else:
            lines_process.append(int(num_lines / num_processes))
    print lines_process
    return lines_process


def chunks(filename, num_processes):
    """
    :param filename: Name of the file to count
    :param num_processes: Number of processes to do the map/reduce
    :return: A matrix [][] with the lines to process for each process
    """
    chunk = []
    chunks = []
    file = open(filename, 'rb')
    for lines in num_lines_file(filename, num_processes):
        chunk = []
        for each_line in range(0, lines):
            chunk.append(file.readline())
        chunks.append(chunk)
    return chunks


def map_reduce():
    return None


if __name__ == "__main__":
    pieces=chunks('logs.txt', 4)
    p = [multiprocessing.Pool(1) for i in range(4)]
    for i, datum in enumerate(pieces): # Show the process and the piece
        p[i%4].map(Map, (datum,))
