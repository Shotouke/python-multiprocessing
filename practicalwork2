__author__ = 'Xavier Domenech & Manuel Rojo'

import py_ecc.file_ecc
import multiprocessing
import random
import os

files = {}
def worker(data):
    """
    This save the name of the file in a dictionary usign its own id as the key
    """
    files[multiprocessing.current_process().name] = data



def worker2(data):
    """
    This worker retrives the name of the file using its own id as the key
    """
    return files[multiprocessing.current_process().name]


def fail_workers(pool, failures):
    """
    This function emulates failing nodes/processes by terminating the
    number of "failures" processes from the "pool".
    """
    if failures > pool._processes:
        raise Exception("You want to fail {} workers from a total of {}, but you can't!!".format(failures, pool._processes))

    ids = random.sample(range(pool._processes), failures)
    for i in ids:
        "emulating a worker fails via its terminate()"
        pool._pool[i].terminate()
        pool._pool[i].join()

    "after failing processes, we need to recover the amount of processes in the pool"
    #pool._maintain_pool()


def test_reed_salomon(size, recover, testFile, decodedFile):
    """
    Method to do the test for the first part of the practical work
    here we can code the original into n pieces, and then we recover it.

    size => Number of processes (number of file parts).
    recover => Number of minimum parts to recover the original data.
    pieces => Array of pieces to recover the original data.
    testFile => A reasonable size file for testing.
    decodedFile => Name of the output file after the recovery
    """
    print "### Running test_reed_salomon with {} processes".format(size)
    p = multiprocessing.Pool(size)
    prefix = testFile + '_backup'
    names = py_ecc.file_ecc.EncodeFile(testFile,prefix,size,recover)

    """First we save the names of the files in each worker """
    p.map(worker, names)

    """now we tretrive the value from the workers"""
    returnedData = p.map(worker2, names)

    decList = []
    for i in range(recover):
        decList.append(returnedData[i])
    print decList

    py_ecc.file_ecc.DecodeFiles(decList,decodedFile) # Decode the file

    p.terminate()
    p.join()

    # Study
    fileSize = os.path.getsize(testFile) # File size
    print 'File size: ' + str(fileSize) + 'bits'

    pieceSize = os.path.getsize(prefix + '.p_' + str(0)) # Piece size
    print 'Piece size: ' + str(pieceSize) + 'bits'


def test_reed_salomon_elasticity(size, recover, fail, testFile, decodedFile):
    """
    Method to do the test for the second part of the practical work
    here we can distribute the pieces in different processes

    size => Number of processes (number of file parts).
    recover => Number of minimum parts to recover the original data.
    fail => Number of processes that we want fail
    testFile => A reasonable size file for testing.
    decodedFile => Name of the output file after the recovery
    """
    print "### Running test_reed_salomon_elasticity with {} processes".format(size)
    p = multiprocessing.Pool(size)
    prefix = testFile + '_backup'
    names = py_ecc.file_ecc.EncodeFile(testFile,prefix,size,recover)



    """First we save the names of the files in each worker """
    p.map(worker, names)

    """Now we kill the processes"""
    fail_workers(p, fail)

    """and we retrive the names from the workers"""
    x=[]
    for i in range(size-fail):
        x.append(i)

    print x
    returnedData = p.map(worker2, x)

    print returnedData

    decList = []
    for i in range(recover):
        decList.append(returnedData[i])
    print decList

    py_ecc.file_ecc.DecodeFiles(decList,decodedFile) # Decode the file

    p.terminate()
    p.join()

    # Study
    fileSize = os.path.getsize(testFile) # File size
    print 'File size: ' + str(fileSize) + 'bits'

    pieceSize = os.path.getsize(prefix + '.p_' + str(0)) # Piece size
    print 'Piece size: ' + str(pieceSize) + 'bits'


if __name__ == "__main__":

    # First part of the practical work: Reed Salomon for storage

    test_reed_salomon(8, 2, 'tmp/testA1', 'tmp/testA1.r') # first test with erasure codes 8,2
    test_reed_salomon(8, 4, 'tmp/testA2', 'tmp/testA2.r') # second test with erasure codes 8,4
    test_reed_salomon(8, 7, 'tmp/testA3', 'tmp/testA3.r') # third test with erasure codes 8,7

    # Second part of the practical work: Elasticity and Reed Salomon

    test_reed_salomon_elasticity(8, 2, 2, 'tmp/testB', 'tmp/testB.r') # first test with erasure codes with elasticity
